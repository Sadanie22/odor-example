{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMqt9CSASeLr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"datar.csv\"\n",
        "data = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "EgouN5HWVxdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "vtWl5Pbxi4Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['odor_labels_filtered'] = data['odor_labels_filtered'].apply(eval)"
      ],
      "metadata": {
        "id": "-RvgOzeKkMVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "labels_binary_matrix = mlb.fit_transform(data['odor_labels_filtered'])\n",
        "labels_df = pd.DataFrame(labels_binary_matrix, columns=mlb.classes_)"
      ],
      "metadata": {
        "id": "H4WLeT3hkNZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data[data['labels_train/test'] == 1].drop(['odor_labels_filtered', 'labels_train/test'], axis=1).iloc[:,2:]\n",
        "X_test = data[data['labels_train/test'] == 0].drop(['odor_labels_filtered', 'labels_train/test'], axis=1).iloc[:,2:]\n",
        "\n",
        "y_train = labels_df[data['labels_train/test'] == 1]\n",
        "y_test = labels_df[data['labels_train/test'] == 0]\n"
      ],
      "metadata": {
        "id": "VPRCqifIjzj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cleaned = X_train.dropna()\n",
        "X_test_cleaned = X_test.dropna()\n",
        "\n",
        "dropped_indices_train = X_train.index.difference(X_train_cleaned.index)\n",
        "dropped_indices_test = X_test.index.difference(X_test_cleaned.index)\n",
        "\n",
        "y_train_cleaned = y_train.drop(index=dropped_indices_train)\n",
        "y_test_cleaned = y_test.drop(index=dropped_indices_test)"
      ],
      "metadata": {
        "id": "RZUgeiKModQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# This was chosen random and needs to be optimized\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=1000,\n",
        "    max_depth=30,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='sqrt',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "rf.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "y_pred_proba = rf.predict_proba(X_test_cleaned)\n",
        "\n",
        "\n",
        "y_pred_proba = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
        "\n",
        "auc_scores = []\n",
        "for i in range(y_test_cleaned.shape[1]):\n",
        "    auc_score = roc_auc_score(y_test_cleaned.iloc[:, i], y_pred_proba[:, i])\n",
        "    auc_scores.append(auc_score)\n",
        "    print(f\"AUROC for {y_test_cleaned.columns[i]}: {auc_score}\")\n",
        "\n",
        "avg_auc = np.mean(auc_scores)\n",
        "print(f\"Average AUROC: {avg_auc}\")\n"
      ],
      "metadata": {
        "id": "lqF_kodICivH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}